import streamlit as st
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv

load_dotenv()

# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(page_title="Smart Document Assistant", layout="wide")
st.header("üìÑ Smart Document Assistant (Powered by Gemini)")

# 2. Sidebar ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏™‡πà API Key ‡πÅ‡∏•‡∏∞ Upload File
with st.sidebar:
    st.title("Settings")
    language = st.radio("Select Answer Language:", ("English", "Thai"))
    
    # ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á Key ‡∏à‡∏≤‡∏Å .env ‡∏Å‡πà‡∏≠‡∏ô
    if os.getenv("GOOGLE_API_KEY"):
        api_key = os.getenv("GOOGLE_API_KEY")
        st.success("‚úÖ API Key loaded from .env")
    else:
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô .env ‡∏Ñ‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏≠‡∏á
        api_key = st.text_input("Enter Google API Key:", type="password")

    uploaded_file = st.file_uploader("Upload PDF File", type="pdf")
    
    if st.button("Submit & Process"):
        if not api_key:
            st.error("Please enter your API Key")
        elif not uploaded_file:
            st.error("Please upload a PDF file")
        else:
            with st.spinner("Processing..."):
                # Save file ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πà‡∏≤‡∏ô
                with open("temp.pdf", "wb") as f:
                    f.write(uploaded_file.getbuffer())
                
                # --- ‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: Data Pipeline ---
                # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå PDF
                loader = PyPDFLoader("temp.pdf")
                docs = loader.load()
                
                # ‡∏´‡∏±‡πà‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏¥‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡πÜ (Chunks)
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                final_documents = text_splitter.split_documents(docs)
                
                # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Vector (Embeddings) ‡∏î‡πâ‡∏ß‡∏¢ Gemini
                embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=api_key)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á Database ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (Vector Store)
                vector_store = FAISS.from_documents(final_documents, embeddings)
                vector_store.save_local("faiss_index")
                
                st.success("Done! You can now ask questions.")

# 3. ‡∏™‡πà‡∏ß‡∏ô‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö (User Interface)
user_question = st.text_input("Ask a question about your PDF:")

if user_question and api_key:
    # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏°‡∏µ Database ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á ---
    if os.path.exists("faiss_index"):
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡πà‡∏≠‡∏¢‡πÇ‡∏´‡∏•‡∏î
        embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=api_key)
        new_db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        docs = new_db.similarity_search(user_question)

        # ... (‡∏™‡πà‡∏ß‡∏ô Prompt Template ‡πÅ‡∏•‡∏∞ Gemini ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...
        prompt_template = f"""
        You are an intelligent assistant for document analysis.
        
        Context:
        {{context}}
        
        Question:
        {{question}}

        Instructions:
        1. Answer purely based on the given Context.
        2. If the answer is not in the context, state "Information not found in the document."
        3. Keep the answer professional and concise.
        4. Answer in {language} language only.
        
        Answer:
        """
        
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = ChatGoogleGenerativeAI(model="models/gemini-flash-latest", google_api_key=api_key, temperature=0.3)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        
        with st.spinner("Thinking..."):
            response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
            st.write("### Answer:")
            st.write(response["output_text"])
            
    else:
        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏î‡∏µ‡πÜ
        st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡πÅ‡∏•‡∏∞‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° 'Submit & Process' ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏£‡∏±‡∏ö")